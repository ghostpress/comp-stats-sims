---
title: "Simulations for Norm Estimation by Sampling"
author: "Lucia Vilallonga"
output: html_notebook
---

## Set Up
```{r}
library(psych)  # for the trace method
```

## Methods
```{r}
# A method to draw a random test matrix with isotropic column vectors.
# Recall that:
#  * an isotropic vector w is one with the property E[w %*% t(w)] = I
#
# Parameters
# ----------
# n :  int
#      The number of rows
# k :  int
#      The number of columns
#
# Returns
# -------
# O :  matrix()
#      The test matrix
#
drawTestM <- function(n, k) {
  
  O <- NULL # matrix(0, nrow=n, ncol=k)
  
  for(i in (1:k)) {
    # Draw an isotropic column vector, eg. from the Gaussian distr. with variance=1
    col <- matrix(rnorm(n, mean=0, sd=1), nrow=n, ncol=1)
    O <- cbind(O, col)
  }
  
  return(O)
}
```

```{r}
# A method to compute the true (l-2p)^2p norm of a matrix, to compare with the estimate.
#
# Parameters
# ----------
# A :  matrix()
#      The nxm matrix for which to compute the norm
#
# Returns
# -------
# nrm : double
#       The (l-2p)^2p norm of the input matrix   
#
computeNorm <- function(A, p) {
  n <- nrow(A)
  m <- ncol(A)
  
  sing_vals <- svd(A)$d
  nrm <- 0
  
  for(i in (1:min(m,n))) {
    nrm <- nrm + (sing_vals[i]^(2*p))
  }
  
  nrm <- nrm^(1/(2*p))
  
  return(nrm^(2*p))
}
```

```{r}
# A method to compute an unbiased estimator for the l-2p norm of a matrix.
# The method uses: a random test matrix (see drawTestM()); matrix-vector multiplication; 
# and a linear map from the space of self-adjoint square matrices to 
# the space of general square upper triangular matrices.
# Recall that:
#  * the l-2p norm of a matrix is the 2p-root sum of its elements^2p
#  * an unbiased estimator has an expected value equal to the quantity to be estimated
#  * an isotropic vector w is one with the property E[w %*% t(w)] = I
# For proof that this method does produce an unbiased estimator for the l-2p norm of a
# matrix, please see the accompanying proofs.pdf file.
#
# Parameters
# ----------
# B :  matrix()
#      The mxn matrix for which to estimate the l-2p norm
# p :  int
#      The power >0 of the norm
# k :  int
#      The number of samples to take
#
# Returns
# -------
# V : double
#     The estimate of the l-2p norm
#
schattenEstimate <- function(B, p, k) {
  m <- nrow(B)
  n <- ncol(B)
  
  O <- drawTestM(n, k)  # draw the test matrix (nxk)
  Y <- B %*% O          # compute the sample matrix (mxk)
  X <- t(Y) %*% Y       # compute the Gram matrix (kxk)   

  # Extract the strict upper triangle of X  
  T_p <- X
  T_p[lower.tri(T_p)] <- 0  # set the lower triangle to 0
  diag(T_p) <- 0            # set the diagonals to 0
  
  # Compute T^(p-1) by repeated multiplication
  if(p > 1) {
    for(i in (1:p-1)) {
      T_p <- T_p %*% T_p
    }
  } else if(p == 1) {
    T_p <- matrix(1, nrow=k, ncol=k)  # T^(p-1) = T^0
  }
  
  # Compute and return the estimate of the norm
  V <- (1/choose(k, p)) * tr(T_p %*% X) 
  return(V)
}
```

```{r}
# A method to compute the error of the estimate as compared to the true value.
# 
# Parameters
# ----------
# a,b  :  list 
#         The two lists to compare
# 
# Returns
# -------
# errs :  list
#         The absolute errors for each element in the lists ($abs), 
#         the mean error ($avg),  
#         and the mean squared error ($mse)
#
computeErr <- function(a, b) {
  
  abs <- matrix(0, nrow=1, ncol=length(a))
  avg <- 0
  rms <- 0
  
  # Compute the absolute error
  for(i in 1:length(a)) {
    abs[i] <- abs(a[[i]] - b[[i]])
  }
  
  # Compute the mean error
  sum <- sum(abs)
  avg <- sum / length(a)
  
  # Compute the root mean squared error (RMSE)
  for(i in 1:length(a)) {
    rms[i] <- sqrt((a[[i]] - b[[i]])^2) / length(a)
  }
  
  return(list("abs" = abs, "avg" = avg, "rms" = rms))
}             
```

## Testing
```{r}
set.seed(987654321)

C <- matrix(rnorm(10*15), nrow=10, ncol=15)  # generate a random mxn matrix for the simulation

#computeNorm(C, 0.5)  # THIS METHOD IS CORRECT
#schattenEstimate(C, 0.5, 10)
computeNorm(C, 1)
schattenEstimate(C, 1, 10)
computeNorm(C, 2)
schattenEstimate(C, 2, 10)
computeNorm(C, 3)
schattenEstimate(C, 3, 10)

```

## Simulation: Is the Estimate Faster? How Accurate is it?
```{r}
set.seed(987654321)

# Fix m = 100, n = 200
n <- 100
m <- 200

# Set up varying values for p (the power of the norm) and k (the number of samples)
P <- seq(1, 100)
K <- seq(2, 200) # FIXME: change to 200, 400 ? -> need the choose(k, p) to not return 0, as it does if k < p

A <- matrix(rnorm(m*n), nrow=m, ncol=n)  # generate a random mxn matrix for the simulation

# Create a dataframe for the results
results <- data.frame(matrix(ncol=7, nrow=length(P) * length(K)))
colnames(results) <- c("p", "k", "Estimate", "TrueValue", "RMSE", "RuntimeEst", "RuntimeTrue")

index_true <- 1
index_est  <- 1

for(p in c(1, 2, 3)) {
  
  # Compute the true Schatten-2p norm and record the runtime
  start <- Sys.time()
  
  norm_true <- computeNorm(A, p)
  runtime   <- Sys.time() - start
  
  # Record the true value and run time in the next length(K) rows
  for(i in index_true:(index_true + length(K) - 1)) {
    results[i, "RuntimeTrue"] <- runtime
    results[i, "TrueValue"]   <- norm_true
  }
  
  index_true <- index_true + length(K)
  
  # Compute the estimate of the Schatten-2p norm for each number of samples k and record the runtime
  for(k in K) {
    results[index_est, "p"] <- p
    results[index_est, "k"] <- k

    # Compute the estimate of the Schatten-2p norm and record the runtime
    new_start <- Sys.time()
  
    norm_est <- schattenEstimate(A, p, k)
    results[index_est, "RuntimeEst"] <- Sys.time() - new_start
    results[index_est, "Estimate"]   <- norm_est
  
    index_est <- index_est + 1
  }
}

break;

# Compute the errors
for(i in 1:nrow(results)) {
  results[i, "RMSE"] <- computeErr(results[i, "Estimate"], results[i, "TrueValue"])$rms
}

# TODO:
#   drop rows where k < p -> 
```

## Plot the Results
```{r}
# TODO: 
#   plot runtime vs k vs p
#   plot errors vs k vs p
#   on each of the above, plot y=k >= 100^(1-2/p)
```